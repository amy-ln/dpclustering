{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2616ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from evaluation_utils import kmeans_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2111260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the synthetic gaussian dataset\n",
    "# dimension 3, centers 4, size 400\n",
    "\n",
    "generator = np.random.default_rng(42)\n",
    "\n",
    "centers = generator.uniform(low=0, high=10, size=(4, 3))\n",
    "dataset = np.concat([generator.multivariate_normal(mean=c, cov=np.identity(3), size=125) for c in centers], axis=0)\n",
    "\n",
    "scaler = MinMaxScaler((-1,1))\n",
    "normalised_dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "np.save(\"synthetic-gaussian.npy\", normalised_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c3eb26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, loss=0.6279472678265365\n",
      "k=2, loss=0.22728119707756012\n",
      "k=3, loss=0.14904959626374673\n",
      "k=4, loss=0.09404854544826846\n",
      "k=5, loss=0.08623461851096122\n",
      "k=6, loss=0.07606246804934169\n",
      "k=7, loss=0.07145971910410755\n",
      "k=8, loss=0.06600693803712546\n",
      "k=9, loss=0.06066679564999772\n",
      "k=10, loss=0.05669602332745931\n"
     ]
    }
   ],
   "source": [
    "synthetic_gaussian = np.load(\"synthetic-gaussian.npy\")\n",
    "\n",
    "# vary the target number of clusters\n",
    "\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=k).fit(synthetic_gaussian)\n",
    "    loss = kmeans_loss(kmeans.cluster_centers_, synthetic_gaussian)\n",
    "    print(f\"k={k}, loss={loss}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8899ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\"datasets/World_Airports.csv\")\n",
    "airports = airports[(airports[\"type\"] == \"large_airport\") | (airports[\"type\"] == \"medium_airport\")][[\"X\", \"Y\"]].dropna().to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler((-1,1))\n",
    "normalised_dataset = scaler.fit_transform(airports)\n",
    "\n",
    "np.save(\"datasets/airports.npy\", normalised_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90573c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, loss=0.2809400945640919\n",
      "k=2, loss=0.11174172858736868\n",
      "k=3, loss=0.0650399484829071\n",
      "k=4, loss=0.050561565371525515\n",
      "k=5, loss=0.03994199410853103\n",
      "k=6, loss=0.03050875532795339\n",
      "k=7, loss=0.026943350656562143\n",
      "k=8, loss=0.024860611634793053\n",
      "k=9, loss=0.020575179769925827\n",
      "k=10, loss=0.01973840819033864\n"
     ]
    }
   ],
   "source": [
    "airports = np.load(\"datasets/airports.npy\")\n",
    "\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=k).fit(airports)\n",
    "    loss = kmeans_loss(kmeans.cluster_centers_, airports)\n",
    "    print(f\"k={k}, loss={loss}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DP Clustering)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
